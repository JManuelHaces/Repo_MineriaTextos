{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(120000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', 900)\n",
    "%autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                                             text\n0                                                                                             @VirginAmerica What @dhepburn said.\n1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.\n2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!\n3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n4                                                                         @VirginAmerica and it's a really big bad thing about it",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@VirginAmerica What @dhepburn said.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@VirginAmerica and it's a really big bad thing about it</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(r'.\\data\\twitter-airline\\Tweets.csv', usecols=['text'])\n",
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                            text\n0                                                                                                   What   said.\n1                                                      plus you've added commercials to the experience... tacky.\n2                                                       I didn't today... Must mean I need to take another trip!\n3    it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces   they have little recourse\n4                                                                       and it's a really big bad thing about it",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What   said.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>plus you've added commercials to the experience... tacky.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I didn't today... Must mean I need to take another trip!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces   they have little recourse</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and it's a really big bad thing about it</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "HANDLE = '@\\w+'\n",
    "LINK = 'https?:t/.co/\\w+'\n",
    "SPECIAL_CHARS = '&lt;|&lt;|&amp;|#'\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(HANDLE, ' ', text)\n",
    "    text = re.sub(LINK, ' ', text)\n",
    "    text = re.sub(SPECIAL_CHARS, ' ', text)\n",
    "    return text\n",
    "\n",
    "tweets['text'] = tweets.text.apply(clean)\n",
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "tweets = tweets.text.apply(preprocess_string).tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "dictionary = corpora.Dictionary(tweets)\n",
    "corpus = [dictionary.doc2bow(text) for text in tweets]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "NUM_TOPICS = 10\n",
    "\n",
    "ldamodel = LdaModel(corpus,\n",
    "                    num_topics=NUM_TOPICS,\n",
    "                    id2word=dictionary,\n",
    "                    passes=15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def calculate_coherence_score(documents, dictionary, model):\n",
    "    coherence_model = CoherenceModel(model=model,\n",
    "                                     texts=documents,\n",
    "                                     dictionary=dictionary,\n",
    "                                     coherence='c_v')\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "def get_coherence_values(start, stop):\n",
    "    for num_topics in range(start, stop):\n",
    "        ldamodel = LdaModel(corpus,\n",
    "                            num_topics=num_topics,\n",
    "                            id2word=dictionary,\n",
    "                            passes=2)\n",
    "        coherence = calculate_coherence_score(tweets,\n",
    "                                              dictionary,\n",
    "                                              ldamodel)\n",
    "        yield coherence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\queues.py\", line 247, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\connection.py\", line 285, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] Se está cerrando la canalización\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\queues.py\", line 247, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\connection.py\", line 285, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] Se está cerrando la canalización\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\queues.py\", line 247, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\connection.py\", line 285, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] Se está cerrando la canalización\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\queues.py\", line 247, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\JManuel\\anaconda3\\envs\\ITESO_Anaconda\\lib\\multiprocessing\\connection.py\", line 285, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] Se está cerrando la canalización\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m min_topics, max_topics \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m30\u001B[39m\n\u001B[1;32m----> 3\u001B[0m coherence_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mget_coherence_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmin_topics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_topics\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36mget_coherence_values\u001B[1;34m(start, stop)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m num_topics \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(start, stop):\n\u001B[0;32m     12\u001B[0m     ldamodel \u001B[38;5;241m=\u001B[39m LdaModel(corpus,\n\u001B[0;32m     13\u001B[0m                         num_topics\u001B[38;5;241m=\u001B[39mnum_topics,\n\u001B[0;32m     14\u001B[0m                         id2word\u001B[38;5;241m=\u001B[39mdictionary,\n\u001B[0;32m     15\u001B[0m                         passes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 16\u001B[0m     coherence \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_coherence_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtweets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mdictionary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mldamodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m coherence\n",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36mcalculate_coherence_score\u001B[1;34m(documents, dictionary, model)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalculate_coherence_score\u001B[39m(documents, dictionary, model):\n\u001B[0;32m      4\u001B[0m     coherence_model \u001B[38;5;241m=\u001B[39m CoherenceModel(model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m      5\u001B[0m                                      texts\u001B[38;5;241m=\u001B[39mdocuments,\n\u001B[0;32m      6\u001B[0m                                      dictionary\u001B[38;5;241m=\u001B[39mdictionary,\n\u001B[0;32m      7\u001B[0m                                      coherence\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc_v\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcoherence_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_coherence\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\models\\coherencemodel.py:615\u001B[0m, in \u001B[0;36mCoherenceModel.get_coherence\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    606\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_coherence\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    607\u001B[0m     \u001B[38;5;124;03m\"\"\"Get coherence value based on pipeline parameters.\u001B[39;00m\n\u001B[0;32m    608\u001B[0m \n\u001B[0;32m    609\u001B[0m \u001B[38;5;124;03m    Returns\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    613\u001B[0m \n\u001B[0;32m    614\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 615\u001B[0m     confirmed_measures \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_coherence_per_topic\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    616\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregate_measures(confirmed_measures)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\models\\coherencemodel.py:587\u001B[0m, in \u001B[0;36mCoherenceModel.get_coherence_per_topic\u001B[1;34m(self, segmented_topics, with_std, with_support)\u001B[0m\n\u001B[0;32m    584\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    585\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnormalize\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoherence \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc_npmi\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 587\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m measure\u001B[38;5;241m.\u001B[39mconf(segmented_topics, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accumulator, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:177\u001B[0m, in \u001B[0;36mcosine_similarity\u001B[1;34m(segmented_topics, accumulator, topics, measure, gamma, with_std, with_support)\u001B[0m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (w_prime, w_star) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(topic_segments):\n\u001B[0;32m    176\u001B[0m     w_prime_cv \u001B[38;5;241m=\u001B[39m context_vectors[w_prime, topic_words]\n\u001B[1;32m--> 177\u001B[0m     w_star_cv \u001B[38;5;241m=\u001B[39m \u001B[43mcontext_vectors\u001B[49m\u001B[43m[\u001B[49m\u001B[43mw_star\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopic_words\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    178\u001B[0m     segment_sims[i] \u001B[38;5;241m=\u001B[39m _cossim(w_prime_cv, w_star_cv)\n\u001B[0;32m    180\u001B[0m topic_coherences\u001B[38;5;241m.\u001B[39mappend(aggregate_segment_sims(segment_sims, with_std, with_support))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:248\u001B[0m, in \u001B[0;36mContextVectorComputer.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m--> 248\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_context_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:269\u001B[0m, in \u001B[0;36mContextVectorComputer.compute_context_vector\u001B[1;34m(self, segment_word_ids, topic_word_ids)\u001B[0m\n\u001B[0;32m    267\u001B[0m context_vector \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext_vector_cache\u001B[38;5;241m.\u001B[39mget(key, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    268\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context_vector \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 269\u001B[0m     context_vector \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_seg\u001B[49m\u001B[43m(\u001B[49m\u001B[43msegment_word_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopic_word_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    270\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext_vector_cache[key] \u001B[38;5;241m=\u001B[39m context_vector\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m context_vector\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:296\u001B[0m, in \u001B[0;36mContextVectorComputer._make_seg\u001B[1;34m(self, segment_word_ids, topic_word_ids)\u001B[0m\n\u001B[0;32m    294\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m pair \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28msorted\u001B[39m((w_i, w_j))) \u001B[38;5;28;01mfor\u001B[39;00m w_i \u001B[38;5;129;01min\u001B[39;00m segment_word_ids):\n\u001B[0;32m    295\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m pair \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msim_cache:\n\u001B[1;32m--> 296\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msim_cache[pair] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimilarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpair\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccumulator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    298\u001B[0m         context_vector[idx] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msim_cache[pair] \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgamma\n\u001B[0;32m    300\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m context_vector\u001B[38;5;241m.\u001B[39mtocsr()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:319\u001B[0m, in \u001B[0;36m_pair_npmi\u001B[1;34m(pair, accumulator)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_pair_npmi\u001B[39m(pair, accumulator):\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute normalized pairwise mutual information (**NPMI**) between a pair of words.\u001B[39;00m\n\u001B[0;32m    305\u001B[0m \n\u001B[0;32m    306\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    317\u001B[0m \n\u001B[0;32m    318\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 319\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlog_ratio_measure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpair\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\topic_coherence\\direct_confirmation_measure.py:193\u001B[0m, in \u001B[0;36mlog_ratio_measure\u001B[1;34m(segmented_topics, accumulator, normalize, with_std, with_support)\u001B[0m\n\u001B[0;32m    191\u001B[0m w_prime_count \u001B[38;5;241m=\u001B[39m accumulator[w_prime]\n\u001B[0;32m    192\u001B[0m w_star_count \u001B[38;5;241m=\u001B[39m accumulator[w_star]\n\u001B[1;32m--> 193\u001B[0m co_occur_count \u001B[38;5;241m=\u001B[39m \u001B[43maccumulator\u001B[49m\u001B[43m[\u001B[49m\u001B[43mw_prime\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw_star\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m normalize:\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;66;03m# For normalized log ratio measure\u001B[39;00m\n\u001B[0;32m    197\u001B[0m     numerator \u001B[38;5;241m=\u001B[39m log_ratio_measure([[(w_prime, w_star)]], accumulator)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py:132\u001B[0m, in \u001B[0;36mBaseAnalyzer.__getitem__\u001B[1;34m(self, word_or_words)\u001B[0m\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_occurrences(word_or_words)\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 132\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_co_occurrences\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mword_or_words\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py:213\u001B[0m, in \u001B[0;36mUsesDictionary.get_co_occurrences\u001B[1;34m(self, word1, word2)\u001B[0m\n\u001B[0;32m    211\u001B[0m word_id1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_word2_contiguous_id(word1)\n\u001B[0;32m    212\u001B[0m word_id2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_word2_contiguous_id(word2)\n\u001B[1;32m--> 213\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_co_occurrences\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword_id1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword_id2\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py:395\u001B[0m, in \u001B[0;36mWordOccurrenceAccumulator._get_co_occurrences\u001B[1;34m(self, word_id1, word_id2)\u001B[0m\n\u001B[0;32m    394\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_co_occurrences\u001B[39m(\u001B[38;5;28mself\u001B[39m, word_id1, word_id2):\n\u001B[1;32m--> 395\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_co_occurrences\u001B[49m\u001B[43m[\u001B[49m\u001B[43mword_id1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword_id2\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\scipy\\sparse\\_index.py:47\u001B[0m, in \u001B[0;36mIndexMixin.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m---> 47\u001B[0m     row, col \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;66;03m# Dispatch to specialized methods.\u001B[39;00m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(row, INT_TYPES):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\scipy\\sparse\\_index.py:152\u001B[0m, in \u001B[0;36mIndexMixin._validate_indices\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    149\u001B[0m M, N \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m    150\u001B[0m row, col \u001B[38;5;241m=\u001B[39m _unpack_index(key)\n\u001B[1;32m--> 152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43misintlike\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    153\u001B[0m     row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(row)\n\u001B[0;32m    154\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m row \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m-\u001B[39mM \u001B[38;5;129;01mor\u001B[39;00m row \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m M:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ITESO_Anaconda\\lib\\site-packages\\scipy\\sparse\\_sputils.py:205\u001B[0m, in \u001B[0;36misintlike\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;124;03m\"\"\"Is x appropriate as an index into a sparse matrix? Returns True\u001B[39;00m\n\u001B[0;32m    201\u001B[0m \u001B[38;5;124;03mif it can be cast safely to a machine int.\u001B[39;00m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    203\u001B[0m \u001B[38;5;66;03m# Fast-path check to eliminate non-scalar values. operator.index would\u001B[39;00m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;66;03m# catch this case too, but the exception catching is slow.\u001B[39;00m\n\u001B[1;32m--> 205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m<__array_function__ internals>:179\u001B[0m, in \u001B[0;36mndim\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "min_topics, max_topics = 10, 30\n",
    "\n",
    "coherence_score = list(get_coherence_values(min_topics, max_topics))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prueba con el Modelo LDAMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "def calculate_coherence_score(documents, dictionary, model):\n",
    "    coherence_model = CoherenceModel(model=model,\n",
    "                                     texts=documents,\n",
    "                                     dictionary=dictionary,\n",
    "                                     coherence='c_v')\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "def get_coherence_values(start, stop):\n",
    "    for num_topics in range(start, stop):\n",
    "        print(f'Calculating Coherence for {num_topics} topics.')\n",
    "        lda = LdaMulticore(corpus,\n",
    "                           num_topics=num_topics,\n",
    "                           id2word=dictionary,\n",
    "                           passes=2)\n",
    "        coherence = calculate_coherence_score(tweets,\n",
    "                                              dictionary,\n",
    "                                              lda)\n",
    "        yield coherence"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
